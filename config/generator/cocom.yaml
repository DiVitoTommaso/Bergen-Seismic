init_args: 
    _target_: models.generators.llm_cocom.LLMCocom
    model_name: null
    checkpoint_path: null
    batch_size: 64
    decoder_model_name: 'mistralai/Mistral-7B-Instruct-v0.2'
    context_max_length: 128
    max_new_tokens: 128
    model_max_length: 1280
    compr_rate: null
    compr_model_name: null
    compr_n_layers: null
    quantization: 'no'
